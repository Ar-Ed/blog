{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: VGG Paper Implementation from Scratch\n",
    "author: Aras Ede≈ü\n",
    "date: '2023-06-29'\n",
    "categories:\n",
    "  - IN PROGRESS\n",
    "  - Deep Learning\n",
    "  - PyTorch\n",
    "  - VGG\n",
    "image: vgg16.png\n",
    "execute: \n",
    "  enabled: false\n",
    "editor:\n",
    "  render-on-save: true\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this article I will be guiding you through the implementation of [VGG paper](https://arxiv.org/abs/1409.1556). VGG paper is published in 2015. Title of the paper is \"Very Deep Convolutional Networks for Large-Scale Image Recognition\". I agree, quite a mouthful but the proposed models managed to place second place in Classification and first place in Localization for ImageNet 2014 Challange. Mainly, authors investigate the following:\n",
    "\n",
    "1. Use of deeper networks (Convolutional that is)\n",
    "2. Small filter sizes (3x3 and 1x1)\n",
    "3. Systematically decreasing feature size and increasing filter count\n",
    "\n",
    "Architectures presented in the paper consist of Conv, MaxPool, Fully-Connected layers and ReLU activation (apart softmax for multi-class classification). Nowadays, BatchNorm is in wide use but it wasn't on the map at the time of this paper (although on one of the architectures utilized LocalResponseNormalization but it is reported to have no benefit). Similarly Dropout layers are not used as well. Layer configurations can be summarized as:\n",
    "\n",
    "1. ReLU Activation after every parametrized layer\n",
    "2. MaxPool layers (2x2) window with stride 2\n",
    "3. Common fully-connected layers accross the proposed architectures\n",
    "4. Convolutional layers with (3x3) and (1x1) filters with \"same\" padding. Filter count ranges from 64 to 512 and incremented by doubling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture Summary\n",
    "Summary of the architectures as given in the paper:\n",
    "\n",
    "|A| A-LRN| B| C| D| E|\n",
    "|---|------|---|----|---|------|\n",
    "|11 layers|  11 layers| 13 layers| 16 layers| 16 layers| 19 layers|\n",
    "|conv3-64| conv3-64| conv3-64| conv3-64| conv3-64| conv3-64|\n",
    "|LRN     | conv3-64| conv3-64| conv3-64| conv3-64| -|\n",
    "|maxpool| maxpool| maxpool| maxpool| maxpool| maxpool|\n",
    "|conv3-128 |conv3-128| conv3-128| conv3-128| conv3-128| conv3-128|\n",
    "|conv3-128 |conv3-128| conv3-128| conv3-128| -| -| \n",
    "|maxpool| maxpool| maxpool| maxpool| maxpool| maxpool|\n",
    "|conv3-256 |conv3-256| conv3-256| conv3-256| conv3-256 conv3-256|\n",
    "|conv3-256 |conv3-256| conv3-256| conv3-256| conv3-256| conv3-256|\n",
    "|conv1-256 |conv3-256| conv3-256| -| -| -|\n",
    "|conv3-256| -| -| -| -| -|\n",
    "|maxpool| maxpool| maxpool| maxpool| maxpool| maxpool|\n",
    "|conv3-512 |conv3-512| conv3-512| conv3-512| conv3-512| conv3-512|\n",
    "|conv3-512 |conv3-512| conv3-512| conv3-512| conv3-512| conv3-512|\n",
    "|conv1-512 |conv3-512| conv3-512| -| -| -|\n",
    "|conv3-512| -| -| -| -| -|\n",
    "|maxpool| maxpool| maxpool| maxpool| maxpool| maxpool|\n",
    "|conv3-512 |conv3-512| conv3-512| conv3-512| conv3-512| conv3-512|\n",
    "|conv3-512 |conv3-512| conv3-512| conv3-512| conv3-512| conv3-512|\n",
    "|conv1-512 |conv3-512| conv3-512| -| -| -|\n",
    "|conv3-512| -| -| -| -| -|\n",
    "|maxpool| maxpool| maxpool| maxpool| maxpool| maxpool|\n",
    "|FC-4096| FC-4096| FC-4096| FC-4096| FC-4096| FC-4096|\n",
    "|FC-4096| FC-4096| FC-4096| FC-4096| FC-4096| FC-4096|\n",
    "|FC-1000| FC-1000| FC-1000| FC-1000| FC-1000| FC-1000|\n",
    "|soft-max |soft-max |soft-max |soft-max |soft-max |soft-max|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.Country211(\"data/\",\n",
    "                                split=\"train\",\n",
    "                                download=True,\n",
    "                                transform=transforms.ToTensor)\n",
    "valid_dataset = datasets.Country211(\"data/\",\n",
    "                                split=\"valid\",\n",
    "                                download=True,\n",
    "                                transform=transforms.ToTensor)\n",
    "test_dataset = datasets.Country211(\"data/\",\n",
    "                                split=\"test\",\n",
    "                                download=True,\n",
    "                                transform=transforms.ToTensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                        batch_size=32,\n",
    "                        shuffle=True,\n",
    "                        num_workers=2)\n",
    "valid_dataloader = DataLoader(valid_dataset,\n",
    "                        batch_size=32,\n",
    "                        shuffle=True,\n",
    "                        num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                        batch_size=32,\n",
    "                        shuffle=True,\n",
    "                        num_workers=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

[
  {
    "objectID": "posts/vgg/index.html",
    "href": "posts/vgg/index.html",
    "title": "VGG Paper Implementation from Scratch",
    "section": "",
    "text": "Introduction\nIn this article I will be guiding throught the implementation of VGG paper. VGG paper is published in 2015. Title of the paper is Very Deep Convolutional Networks for Large-Scale Image Recognition”. I agree, quite a mouthful but the proposed models managed to place second in Classification and first in Localization in ImageNet 2014 Challange. Mainly, they investigate the following:\n\nUse of deeper networks (Convolutional that is)\nSmall filter sizes (3x3 and 1x1)\nSystematically decreasing feature size and increasing filter count\n\nArchitectures presented in the paper consist of Conv, MaxPool, Fully-Connected layers and ReLU activation (apart softmax for multi-class classification). Nowadays, BatchNorm is in wide use but it wasn’t on the map at the time of this paper (although on one of the architectures utilized LocalResponseNormalization but it is reported to have no benefit). Similarly Dropout layers are not used as well. Layer configurations can be summarized as:\n\nReLU Activation after every parametrized layer\nMaxPool layers (2x2) window with stride 2\nCommon fully-connected layers accross the proposed architectures\nConvolutional layers with (3x3) and (1x1) filters with “same” padding. Filter count ranges from 64 to 512 and incremented by doubling\n\n\n\nArchitecture Summary\nSummary of the architectures as given in the paper:\n\n\n\nA\nA-LRN\nB\nC\nD\nE\n\n\n\n\n11 layers\n11 layers\n13 layers\n16 layers\n16 layers\n19 layers\n\n\nconv3-64\nconv3-64\nconv3-64\nconv3-64\nconv3-64\nconv3-64\n\n\nLRN\nconv3-64\nconv3-64\nconv3-64\nconv3-64\n-\n\n\nmaxpool\nmaxpool\nmaxpool\nmaxpool\nmaxpool\nmaxpool\n\n\nconv3-128\nconv3-128\nconv3-128\nconv3-128\nconv3-128\nconv3-128\n\n\nconv3-128\nconv3-128\nconv3-128\nconv3-128\n-\n-\n\n\nmaxpool\nmaxpool\nmaxpool\nmaxpool\nmaxpool\nmaxpool\n\n\nconv3-256\nconv3-256\nconv3-256\nconv3-256\nconv3-256 conv3-256\n\n\n\nconv3-256\nconv3-256\nconv3-256\nconv3-256\nconv3-256\nconv3-256\n\n\nconv1-256\nconv3-256\nconv3-256\n-\n-\n-\n\n\nconv3-256\n-\n-\n-\n-\n-\n\n\nmaxpool\nmaxpool\nmaxpool\nmaxpool\nmaxpool\nmaxpool\n\n\nconv3-512\nconv3-512\nconv3-512\nconv3-512\nconv3-512\nconv3-512\n\n\nconv3-512\nconv3-512\nconv3-512\nconv3-512\nconv3-512\nconv3-512\n\n\nconv1-512\nconv3-512\nconv3-512\n-\n-\n-\n\n\nconv3-512\n-\n-\n-\n-\n-\n\n\nmaxpool\nmaxpool\nmaxpool\nmaxpool\nmaxpool\nmaxpool\n\n\nconv3-512\nconv3-512\nconv3-512\nconv3-512\nconv3-512\nconv3-512\n\n\nconv3-512\nconv3-512\nconv3-512\nconv3-512\nconv3-512\nconv3-512\n\n\nconv1-512\nconv3-512\nconv3-512\n-\n-\n-\n\n\nconv3-512\n-\n-\n-\n-\n-\n\n\nmaxpool\nmaxpool\nmaxpool\nmaxpool\nmaxpool\nmaxpool\n\n\nFC-4096\nFC-4096\nFC-4096\nFC-4096\nFC-4096\nFC-4096\n\n\nFC-4096\nFC-4096\nFC-4096\nFC-4096\nFC-4096\nFC-4096\n\n\nFC-1000\nFC-1000\nFC-1000\nFC-1000\nFC-1000\nFC-1000\n\n\nsoft-max\nsoft-max\nsoft-max\nsoft-max\nsoft-max\nsoft-max\n\n\n\n\n\nImplementation\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision import transforms\n\n\ntrain_dataset = datasets.Country211(\"data/\",\n                                split=\"train\",\n                                download=True,\n                                transform=transforms.ToTensor)\nvalid_dataset = datasets.Country211(\"data/\",\n                                split=\"valid\",\n                                download=True,\n                                transform=transforms.ToTensor)\ntest_dataset = datasets.Country211(\"data/\",\n                                split=\"test\",\n                                download=True,\n                                transform=transforms.ToTensor)\n\ntrain_dataloader = DataLoader(train_dataset,\n                        batch_size=32,\n                        shuffle=True,\n                        num_workers=2)\nvalid_dataloader = DataLoader(valid_dataset,\n                        batch_size=32,\n                        shuffle=True,\n                        num_workers=2)\ntest_dataloader = DataLoader(test_dataset,\n                        batch_size=32,\n                        shuffle=True,\n                        num_workers=2)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blog",
    "section": "",
    "text": "VGG Paper Implementation from Scratch\n\n\n\n\n\n\n\nIN PROGRESS\n\n\nDeep Learning\n\n\nPyTorch\n\n\nVGG\n\n\n\n\n\n\n\n\n\n\n\nJun 29, 2023\n\n\nAras Edeş\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Currently, I am a student at Istanbul Technical University. I like to work on data science and related fields. In this blog I will be writing about mostly machine learning, computer science, and mathematics."
  }
]